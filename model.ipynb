{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n",
    "test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n",
    "test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')\n",
    "\n",
    "# Merge transaction and identity datasets\n",
    "train = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "test = test_transaction.merge(test_identity, on='TransactionID', how='left')\n",
    "\n",
    "# Clean up memory\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "gc.collect()\n",
    "\n",
    "# Feature Engineering (basic example)\n",
    "# Label encoding for categorical variables\n",
    "for col in train.select_dtypes(include=['object']).columns:\n",
    "    if col in test.columns:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))\n",
    "\n",
    "# Fill missing values with -1 (or you can try other imputation methods)\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "# Separate target and features\n",
    "X = train.drop(['isFraud', 'TransactionID'], axis=1)\n",
    "y = train['isFraud']\n",
    "X_test = test.drop(['TransactionID'], axis=1)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LightGBM model\n",
    "model = LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    max_depth=12,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model with callbacks for early stopping and logging\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100),\n",
    "        log_evaluation(100)  # Logs every 100 rounds\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Predict on validation set and evaluate\n",
    "val_preds = model.predict_proba(X_val)[:, 1]\n",
    "roc_score = roc_auc_score(y_val, val_preds)\n",
    "print(f'Validation ROC-AUC score: {roc_score}')\n",
    "\n",
    "# Predict on test set for submission\n",
    "test_preds = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create submission file\n",
    "sample_submission['isFraud'] = test_preds\n",
    "sample_submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
