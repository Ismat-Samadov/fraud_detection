{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Load data\n",
    "train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n",
    "test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n",
    "test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')\n",
    "\n",
    "# Merge transaction and identity tables on TransactionID\n",
    "train_df = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "test_df = test_transaction.merge(test_identity, on='TransactionID', how='left')\n",
    "\n",
    "# Free up memory by deleting unused dataframes\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "# Separate target and drop from train data\n",
    "y = train_df['isFraud']\n",
    "X = train_df.drop(['isFraud', 'TransactionID'], axis=1)\n",
    "test_df = test_df.drop(['TransactionID'], axis=1)\n",
    "\n",
    "# Handle missing values by filling with a constant\n",
    "X.fillna(-999, inplace=True)\n",
    "test_df.fillna(-999, inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(X[col].astype(str).values) + list(test_df[col].astype(str).values))\n",
    "    X[col] = le.transform(list(X[col].astype(str).values))\n",
    "    test_df[col] = le.transform(list(test_df[col].astype(str).values))\n",
    "\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 256,\n",
    "    'max_depth': -1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'min_split_gain': 0.01,\n",
    "    'min_child_weight': 2,\n",
    "    'verbose': -1,\n",
    "    'is_unbalance': True\n",
    "}\n",
    "\n",
    "# KFold cross-validation\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "features = X.columns\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    print(f\"Training fold {fold + 1}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # LightGBM Dataset formatting\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    \n",
    "    # Train the model\n",
    "    clf = lgb.train(params, train_data, valid_sets=[train_data, val_data], \n",
    "                    verbose_eval=500, early_stopping_rounds=100)\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = clf.predict(X_val, num_iteration=clf.best_iteration)\n",
    "    print(f\"Fold {fold + 1} AUC: {roc_auc_score(y_val, val_pred)}\")\n",
    "    \n",
    "    predictions += clf.predict(test_df, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "# Prepare submission\n",
    "sample_submission['isFraud'] = predictions\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
