{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "import absl.logging\n",
    "\n",
    "# Suppress TensorFlow and other unnecessary logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Filter out INFO and WARNING logs\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\"\n",
    "os.environ[\"JAX_LOG_LEVEL\"] = \"ERROR\"\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# TPU setup\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPU\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU\")\n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()  # Default strategy for CPU and single GPU\n",
    "    print(\"Running on CPU or GPU\")\n",
    "\n",
    "# Load data\n",
    "train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')\n",
    "train_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')\n",
    "test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')\n",
    "test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')\n",
    "\n",
    "# Merge transaction and identity datasets\n",
    "train = train_transaction.merge(train_identity, on='TransactionID', how='left')\n",
    "test = test_transaction.merge(test_identity, on='TransactionID', how='left')\n",
    "\n",
    "# Clean up memory\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "gc.collect()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(train, test):\n",
    "    # Label encode categorical features\n",
    "    label_encoders = {}\n",
    "    for col in train.select_dtypes(include=['object']).columns:\n",
    "        if col in test.columns:\n",
    "            le = LabelEncoder()\n",
    "            combined_data = pd.concat([train[col], test[col]], axis=0).astype(str)\n",
    "            le.fit(combined_data)\n",
    "            train[col] = le.transform(train[col].astype(str))\n",
    "            test[col] = le.transform(test[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "\n",
    "    # One-hot encode features with many categories\n",
    "    train = pd.get_dummies(train, drop_first=True)\n",
    "    test = pd.get_dummies(test, drop_first=True)\n",
    "    \n",
    "    # Align train and test data\n",
    "    train, test = train.align(test, join='left', axis=1, fill_value=0)\n",
    "    \n",
    "    # Fill missing values\n",
    "    train.fillna(-1, inplace=True)\n",
    "    test.fillna(-1, inplace=True)\n",
    "    \n",
    "    # Remove special characters from feature names to avoid errors\n",
    "    train.columns = train.columns.str.replace(r'[^A-Za-z0-9_]', '_', regex=True)\n",
    "    test.columns = test.columns.str.replace(r'[^A-Za-z0-9_]', '_', regex=True)\n",
    "    \n",
    "    # Scale numeric features\n",
    "    scaler = StandardScaler()\n",
    "    numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "    train[numeric_cols] = scaler.fit_transform(train[numeric_cols])\n",
    "    test[numeric_cols] = scaler.transform(test[numeric_cols])\n",
    "\n",
    "    return train, test, label_encoders, scaler\n",
    "\n",
    "# Preprocess data\n",
    "train, test, label_encoders, scaler = preprocess_data(train, test)\n",
    "\n",
    "# Check and clean target variable (isFraud) for unexpected values\n",
    "print(\"Unique values in 'isFraud' before cleaning:\", train['isFraud'].unique())\n",
    "train['isFraud'] = train['isFraud'].replace({5: 1})  # Replace 5 with 1 if 5 represents fraud\n",
    "print(\"Unique values in 'isFraud' after cleaning:\", train['isFraud'].unique())\n",
    "\n",
    "# Convert target variable to integer if not already in integer format\n",
    "train['isFraud'] = train['isFraud'].astype(int)\n",
    "\n",
    "# Separate target and features\n",
    "X = train.drop(['isFraud', 'TransactionID'], axis=1)\n",
    "y = train['isFraud']\n",
    "X_test = test.drop(['TransactionID'], axis=1)\n",
    "\n",
    "# Convert to NumPy arrays and ensure compatibility with TPU operations\n",
    "X = np.array(X).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "y = np.array(y).astype('int32')\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network model inside TPU strategy scope\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "# Calculate batch size based on strategy\n",
    "batch_size = 1024\n",
    "if hasattr(strategy, \"num_replicas_in_sync\") and strategy.num_replicas_in_sync:\n",
    "    batch_size *= strategy.num_replicas_in_sync\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=batch_size,  # Adjust batch size for TPU if available\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predict on validation set and evaluate\n",
    "val_preds = model.predict(tf.convert_to_tensor(X_val)).numpy().ravel()\n",
    "roc_score = roc_auc_score(y_val, val_preds)\n",
    "print(f'Validation ROC-AUC score: {roc_score}')\n",
    "\n",
    "# Predict on test set for submission\n",
    "test_preds = model.predict(tf.convert_to_tensor(X_test)).numpy().ravel()\n",
    "\n",
    "# Create submission file\n",
    "sample_submission['isFraud'] = test_preds\n",
    "sample_submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
